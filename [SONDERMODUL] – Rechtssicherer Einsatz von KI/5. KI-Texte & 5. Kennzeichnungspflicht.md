So, jetzt habe ich mir noch einen passenden Text für diesen Newsletter generieren lassen.  
Theoretisch könnte ich den so absenden.  

Trotzdem frage ich mich:  
Ist das eigentlich in Ordnung?  

Wenn ich mich in die Lage anderer Menschen hineinversetze, würde ich schon gerne wissen wollen, ob so ein Text von einer KI geschrieben wurde oder nicht.  

Mensch oder Maschine – den Unterschied kann man oft nicht erkennen.  
Der Ursprung eines Werkes lässt sich teilweise mit bloßem Auge nicht feststellen.  

Genau deshalb tritt mit dem AI Act die Kennzeichnungspflicht in Kraft.  
Sie gilt für sogenannte Systeme mit begrenztem Risiko.  

Ein solches Risiko besteht zum Beispiel bei Bildern, Audiodateien oder Videos, die scheinbar die Realität abbilden – also echte Orte, Personen oder Ereignisse zeigen.  
Zum Beispiel sogenannte Deepfakes.  

Auch wenn sie heute oft für Satire oder Unterhaltung genutzt werden, können sie täuschend echt wirken.  
Deshalb müssen solche Inhalte eindeutig gekennzeichnet werden, etwa durch ein Wasserzeichen oder einen kleinen Hinweis am Rand des Bildes.  

Wie genau die Kennzeichnung aussehen soll, das schreibt das Gesetz allerdings nicht vor.  
Wichtig ist nur, dass sie klar erkennbar ist.  

Ein weiteres sensibles Thema sind KI-generierte Texte, die – so der Wortlaut – die Öffentlichkeit über Angelegenheiten von öffentlichem Interesse informieren.  

Laut AI Act müssen auch solche Texte gekennzeichnet werden, immer dann, wenn sie von einer KI erstellt oder verändert wurden.  

Das kann tatsächlich auf viele Inhalte zutreffen – zum Beispiel auf Pressemitteilungen, Verbraucherhinweise oder Jahresberichte.  

Solltest du also sicherheitshalber jeden Text kennzeichnen, nur um auf Nummer sicheren zu gehen?  

Nicht unbedingt.  
Denn das Gesetz sieht hier eine wichtige Ausnahme vor:  
Wenn der Text von einem Menschen überprüft wurde, gilt die Kennzeichnungspflicht nicht.
